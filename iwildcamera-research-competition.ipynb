{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/khushboos/iwildcamera-research-competition?scriptVersionId=118335981\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport os, json, codecs\nimport cv2 as cv\nimport matplotlib.pyplot as plt\nfrom keras.models import Sequential\nfrom tensorflow.keras.layers import Convolution2D, Dense, MaxPool2D, Activation, Dropout, Flatten, BatchNormalization\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.optimizers import Adam\nnp.random.seed(921)\nfrom keras.utils import np_utils\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n# for dirname, _, filenames in os.walk('/kaggle/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-02-01T12:53:10.508846Z","iopub.execute_input":"2023-02-01T12:53:10.509841Z","iopub.status.idle":"2023-02-01T12:53:10.517788Z","shell.execute_reply.started":"2023-02-01T12:53:10.509791Z","shell.execute_reply":"2023-02-01T12:53:10.516458Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# ----------------Training meta data--------------------------------\nwith codecs.open(\"/kaggle/input/iwildcam2022-fgvc9/metadata/metadata/iwildcam2022_train_annotations.json\",'r', encoding='utf-8', errors = 'ignore') as f :\n    train_anot_meta = json.load(f)\n    \n#--------------- Testing meta data --------------------------------   \nwith codecs.open(\"/kaggle/input/iwildcam2022-fgvc9/metadata/metadata/iwildcam2022_test_information.json\",'r', encoding='utf-8', errors='ignore') as f:\n    test_anot_meta = json.load(f)\n    \n#---------------- Detection meta data--------------------------------\nwith codecs.open(\"/kaggle/input/iwildcam2022-fgvc9/metadata/metadata/iwildcam2022_mdv4_detections.json\",'r', encoding='utf-8', errors='ignore') as f:\n    detection_data = json.load(f)\n    \n#--------------- GPS location meta data-------------------------------------\nwith codecs.open(\"/kaggle/input/iwildcam2022-fgvc9/metadata/metadata/gps_locations.json\",'r', encoding='utf-8', errors='ignore') as f :\n    gps_location = json.load(f)\n# (\"/kaggle/input/iwildcam2022-fgvc9/metadata/metadata/iwildcam2022_train_annotations.json\")","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:19:03.771097Z","iopub.execute_input":"2023-02-01T12:19:03.771686Z","iopub.status.idle":"2023-02-01T12:19:09.106834Z","shell.execute_reply.started":"2023-02-01T12:19:03.771653Z","shell.execute_reply":"2023-02-01T12:19:09.105777Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"Training anotations : {train_anot_meta.keys()}\\\n        \\nTesting Anotation : {test_anot_meta.keys()}\\\n        \\nGps Location : gps_location.keys()\\\n        \\ndetection : {detection_data.keys()}\")","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:19:09.10947Z","iopub.execute_input":"2023-02-01T12:19:09.112188Z","iopub.status.idle":"2023-02-01T12:19:09.118488Z","shell.execute_reply.started":"2023-02-01T12:19:09.112143Z","shell.execute_reply":"2023-02-01T12:19:09.117397Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -----------------Training meta data in pandas dataframe--------------------------------  \ntrain_images = pd.DataFrame(train_anot_meta['images'])\ntrain_anotations = pd.DataFrame(train_anot_meta['annotations'])\ntrain_categories = pd.DataFrame(train_anot_meta['categories'])\nprint(f\"Train images Shape : {train_images.shape}\\\n        \\nAnnotation Shape : {train_anotations.shape}\\\n        \\nTrain_Categories : {train_categories.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:19:09.120181Z","iopub.execute_input":"2023-02-01T12:19:09.121431Z","iopub.status.idle":"2023-02-01T12:19:09.802897Z","shell.execute_reply.started":"2023-02-01T12:19:09.121391Z","shell.execute_reply":"2023-02-01T12:19:09.801859Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -----------------Test meta data in the Pandas datarame-------------------------------------\ntest_images = pd.DataFrame(test_anot_meta['images'])\nprint(f\"Test_images shape :{test_images.shape}\")","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:19:09.805831Z","iopub.execute_input":"2023-02-01T12:19:09.806841Z","iopub.status.idle":"2023-02-01T12:19:09.945716Z","shell.execute_reply.started":"2023-02-01T12:19:09.806809Z","shell.execute_reply":"2023-02-01T12:19:09.944592Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_images","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:19:09.947364Z","iopub.execute_input":"2023-02-01T12:19:09.948046Z","iopub.status.idle":"2023-02-01T12:19:09.984578Z","shell.execute_reply.started":"2023-02-01T12:19:09.948003Z","shell.execute_reply":"2023-02-01T12:19:09.983625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_anotations","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:19:09.986059Z","iopub.execute_input":"2023-02-01T12:19:09.9867Z","iopub.status.idle":"2023-02-01T12:19:09.999799Z","shell.execute_reply.started":"2023-02-01T12:19:09.986661Z","shell.execute_reply":"2023-02-01T12:19:09.998629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_categories","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:19:10.001672Z","iopub.execute_input":"2023-02-01T12:19:10.002393Z","iopub.status.idle":"2023-02-01T12:19:10.016139Z","shell.execute_reply.started":"2023-02-01T12:19:10.002356Z","shell.execute_reply":"2023-02-01T12:19:10.01502Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's check the number of training samles\nprint(f\"Training Sample Length :{len(os.listdir('/kaggle/input/iwildcam2022-fgvc9/train/train'))}\\\n        \\nTesting Sample Length :{len(os.listdir('/kaggle/input/iwildcam2022-fgvc9/test/test'))}\")\n# so the Number of samples are same for both training samples and for the metadata i.e. 201399","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:19:10.017867Z","iopub.execute_input":"2023-02-01T12:19:10.018418Z","iopub.status.idle":"2023-02-01T12:19:14.055179Z","shell.execute_reply.started":"2023-02-01T12:19:10.018364Z","shell.execute_reply":"2023-02-01T12:19:14.053848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Images of an animals ","metadata":{}},{"cell_type":"code","source":"# reading the first image from the training sample and showing it down.\nimg = cv.imread(\"/kaggle/input/iwildcam2022-fgvc9/train/train/86760c00-21bc-11ea-a13a-137349068a90.jpg\")\nprint(f\"Images Shape : {img.shape}\")\nplt.figure(figsize=(10,10))\nplt.imshow(img)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:19:14.057897Z","iopub.execute_input":"2023-02-01T12:19:14.059022Z","iopub.status.idle":"2023-02-01T12:19:14.731834Z","shell.execute_reply.started":"2023-02-01T12:19:14.058976Z","shell.execute_reply":"2023-02-01T12:19:14.730938Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_anotations['image_id']","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:19:14.735382Z","iopub.execute_input":"2023-02-01T12:19:14.736145Z","iopub.status.idle":"2023-02-01T12:19:14.749049Z","shell.execute_reply.started":"2023-02-01T12:19:14.736098Z","shell.execute_reply":"2023-02-01T12:19:14.747845Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Resize Images","metadata":{}},{"cell_type":"code","source":"#-------Taking only 20000 data from the training set-----------------\nimages = train_anotations.image_id[:20000]\nlabels = train_anotations.category_id[:20000]\n\n#--- Reshaping the images ------------------------------\ntrain_images = []\nfor i in images:\n    rd_img = cv.imread(\"/kaggle/input/iwildcam2022-fgvc9/train/train/\"+ i +\".jpg\")\n    res_img = cv.resize(rd_img, (32,32), interpolation=cv.INTER_AREA)\n    train_images.append(res_img)\n    \n# Convert it into the numpy array\ntrain_images = np.array(train_images)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:19:14.750921Z","iopub.execute_input":"2023-02-01T12:19:14.751835Z","iopub.status.idle":"2023-02-01T12:35:22.491031Z","shell.execute_reply.started":"2023-02-01T12:19:14.751779Z","shell.execute_reply":"2023-02-01T12:35:22.489918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# train_images","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:35:22.49283Z","iopub.execute_input":"2023-02-01T12:35:22.493239Z","iopub.status.idle":"2023-02-01T12:35:22.49938Z","shell.execute_reply.started":"2023-02-01T12:35:22.4932Z","shell.execute_reply":"2023-02-01T12:35:22.497934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model Creation","metadata":{}},{"cell_type":"code","source":"#-------------------- Model Creation --------------------------------------------------------\nmodel = Sequential()\n\n#---- 1st Convolution Layer---------\nmodel.add(Convolution2D(filters=32, kernel_size = (3,3), input_shape=(32, 32,3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(rate = 0.35))\n\n#----- 1st Pooling layer-------------\nmodel.add(MaxPool2D(pool_size = (2,2), padding='same'))\n\n#----- 2nd Convolution Layer----------\nmodel.add(Convolution2D(filters= 64, kernel_size=(3,3), padding = 'same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(rate=0.45))\n\n#------2nd pooling Layer--------------\nmodel.add(MaxPool2D(pool_size=(2,2), padding='same'))\nmodel.add(Flatten())\n\n#---- 1st Dense Layer-----------------\nmodel.add(Dense(1024, activation = 'relu'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\nmodel.add(Dropout(rate=0.75))\n\n#------2nd Dense Layer---------------\nmodel.add(Dense(max(labels)+1, activation='softmax'))\n\n#---------------Model Compilation------------------------------------------\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:51:18.447971Z","iopub.execute_input":"2023-02-01T12:51:18.448379Z","iopub.status.idle":"2023-02-01T12:51:18.552906Z","shell.execute_reply.started":"2023-02-01T12:51:18.448346Z","shell.execute_reply":"2023-02-01T12:51:18.552009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training Data Splitting","metadata":{}},{"cell_type":"code","source":"#---------Train test split ---------------------------------\nX_train, X_test, Y_train, y_test = train_test_split(train_images, labels, test_size = 0.2)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:53:16.388696Z","iopub.execute_input":"2023-02-01T12:53:16.389119Z","iopub.status.idle":"2023-02-01T12:53:16.517619Z","shell.execute_reply.started":"2023-02-01T12:53:16.389085Z","shell.execute_reply":"2023-02-01T12:53:16.516309Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#----------- Changeg datatype and reshape the data----------------\nY_train=Y_train.astype(int)\ny_test=y_test.astype(int)\n\n#---------- Reshape Y------------------\nY_train=np.array(Y_train).reshape(-1,1)\ny_test=np.array(y_test).reshape(-1,1)\n\n# -------- Reshape X ------------------\nX_train=X_train.reshape(-1,32,32,3)/255\nX_test=X_test.reshape(-1,32,32,3)/255\n\n#-----------Convert it into Categorical data -------------------\nY_train=np_utils.to_categorical(Y_train,num_classes=max(labels)+1)\ny_test=np_utils.to_categorical(y_test,num_classes=max(labels)+1)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:53:22.588692Z","iopub.execute_input":"2023-02-01T12:53:22.58911Z","iopub.status.idle":"2023-02-01T12:53:28.898237Z","shell.execute_reply.started":"2023-02-01T12:53:22.589074Z","shell.execute_reply":"2023-02-01T12:53:28.897136Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Training","metadata":{}},{"cell_type":"code","source":"#------------ Train the data--------------------\ntrain_history = model.fit(X_train,Y_train,validation_split=0.2,epochs=30,batch_size=200,verbose=1)\n\n#----------- Calculate Accuracy --------------------\naccuracy = model.evaluate(X_test,y_test,verbose=1)\nprint(\"test accuracy:\",accuracy[1])","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:54:00.611051Z","iopub.execute_input":"2023-02-01T12:54:00.611752Z","iopub.status.idle":"2023-02-01T12:55:31.486008Z","shell.execute_reply.started":"2023-02-01T12:54:00.611716Z","shell.execute_reply":"2023-02-01T12:55:31.485012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#------------   Plot the Training accuracy and validation Accuracy -------------------\ndef show_train_history(train_history,train_accuracy,val_accuracy):\n        plt.plot(train_history.history[train_accuracy])\n        plt.plot(train_history.history[val_accuracy])\n        plt.title('Train History')\n        plt.ylabel('train')\n        plt.xlabel('Epoch')\n        plt.legend(['train','validation'],loc='upper left')\n        plt.show()\n\nshow_train_history(train_history,'accuracy','val_accuracy') #acc:accuracy for training set. val_acc:accuracy for validation.","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:55:31.489662Z","iopub.execute_input":"2023-02-01T12:55:31.490057Z","iopub.status.idle":"2023-02-01T12:55:31.76107Z","shell.execute_reply.started":"2023-02-01T12:55:31.490027Z","shell.execute_reply":"2023-02-01T12:55:31.759867Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prediction","metadata":{}},{"cell_type":"code","source":"#----------------- Test Predict (as this test images were from the training data) ----------------\nprediction  = model.predict(X_test)\nprint(prediction)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:55:31.762663Z","iopub.execute_input":"2023-02-01T12:55:31.763064Z","iopub.status.idle":"2023-02-01T12:55:32.322212Z","shell.execute_reply.started":"2023-02-01T12:55:31.763024Z","shell.execute_reply":"2023-02-01T12:55:32.321031Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"32*32*3","metadata":{"execution":{"iopub.status.busy":"2023-02-01T13:25:11.281999Z","iopub.execute_input":"2023-02-01T13:25:11.282418Z","iopub.status.idle":"2023-02-01T13:25:11.289211Z","shell.execute_reply.started":"2023-02-01T13:25:11.282383Z","shell.execute_reply":"2023-02-01T13:25:11.288144Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"{prediction.shape}, {prediction[0]}\")","metadata":{"execution":{"iopub.status.busy":"2023-02-01T13:24:45.626816Z","iopub.execute_input":"2023-02-01T13:24:45.627536Z","iopub.status.idle":"2023-02-01T13:24:45.636033Z","shell.execute_reply.started":"2023-02-01T13:24:45.627496Z","shell.execute_reply":"2023-02-01T13:24:45.634878Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_images","metadata":{"execution":{"iopub.status.busy":"2023-02-01T12:57:52.838481Z","iopub.execute_input":"2023-02-01T12:57:52.838883Z","iopub.status.idle":"2023-02-01T12:57:52.861852Z","shell.execute_reply.started":"2023-02-01T12:57:52.838849Z","shell.execute_reply":"2023-02-01T12:57:52.860921Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#--------------------- test the original test data------------------------\nimages = test_images.id[:20000]\n# test_img_id =test_images.id[:30000]\n\ntest_image = []\nfor i in images:\n    img = cv.imread(\"/kaggle/input/iwildcam2022-fgvc9/test/test/\"+ i +\".jpg\")\n    res_img = cv.resize(img, (32,32),interpolation=cv.INTER_AREA)\n    test_image.append(res_img)\n    \n# Convert it into the numpy array\ntest_image = np.array(test_image)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T13:26:12.551079Z","iopub.execute_input":"2023-02-01T13:26:12.551486Z","iopub.status.idle":"2023-02-01T13:42:33.936866Z","shell.execute_reply.started":"2023-02-01T13:26:12.55144Z","shell.execute_reply":"2023-02-01T13:42:33.934303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# -------- Predicting the original Test data------------\ntest_prediction = model.predict(test_image)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T13:42:34.071862Z","iopub.execute_input":"2023-02-01T13:42:34.072522Z","iopub.status.idle":"2023-02-01T13:42:37.441044Z","shell.execute_reply.started":"2023-02-01T13:42:34.07248Z","shell.execute_reply":"2023-02-01T13:42:37.439531Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prediction","metadata":{"execution":{"iopub.status.busy":"2023-02-01T13:49:48.327338Z","iopub.execute_input":"2023-02-01T13:49:48.327709Z","iopub.status.idle":"2023-02-01T13:49:48.337557Z","shell.execute_reply.started":"2023-02-01T13:49:48.327677Z","shell.execute_reply":"2023-02-01T13:49:48.336494Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_prediction.shape","metadata":{"execution":{"iopub.status.busy":"2023-02-01T13:50:24.414087Z","iopub.execute_input":"2023-02-01T13:50:24.414506Z","iopub.status.idle":"2023-02-01T13:50:24.421393Z","shell.execute_reply.started":"2023-02-01T13:50:24.414469Z","shell.execute_reply":"2023-02-01T13:50:24.420276Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = {\"lists\": list(images)}\nsubmit = pd.DataFrame({'Id':images,'Predicted': list(test_prediction)})\nsubmit.to_csv('submission.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2023-02-01T13:51:19.648652Z","iopub.execute_input":"2023-02-01T13:51:19.649134Z","iopub.status.idle":"2023-02-01T13:52:08.724306Z","shell.execute_reply.started":"2023-02-01T13:51:19.649099Z","shell.execute_reply":"2023-02-01T13:52:08.723297Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"pd.read_csv(\"/kaggle/working/submission.csv\")","metadata":{"execution":{"iopub.status.busy":"2023-02-01T13:53:01.934517Z","iopub.execute_input":"2023-02-01T13:53:01.934916Z","iopub.status.idle":"2023-02-01T13:53:02.077686Z","shell.execute_reply.started":"2023-02-01T13:53:01.934881Z","shell.execute_reply":"2023-02-01T13:53:02.076555Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}